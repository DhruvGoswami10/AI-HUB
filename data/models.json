[
  {
    "id": "model-001",
    "name": "GPT-4o",
    "provider": "OpenAI",
    "params": "1.8T (est.)",
    "context": "128k",
    "modalities": ["Text", "Vision", "Audio"],
    "domains": ["Multimodal", "Assistant"],
    "benchmarks": { "mmlu": 88.5 },
    "efficiency": "86 tokens / s @ A100",
    "link": "https://openai.com/index/gpt-4o-and-gpt-4o-mini/",
    "timestamp": "2024-05-13T10:00:00Z"
  },
  {
    "id": "model-002",
    "name": "Claude 3.5 Sonnet",
    "provider": "Anthropic",
    "params": "860B (est.)",
    "context": "200k",
    "modalities": ["Text", "Vision"],
    "domains": ["Reasoning", "Enterprise"],
    "benchmarks": { "mmlu": 90.0 },
    "efficiency": "75 tokens / s @ H100",
    "link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "timestamp": "2024-06-20T09:00:00Z"
  },
  {
    "id": "model-003",
    "name": "Gemini 1.5 Pro",
    "provider": "Google",
    "params": "1.6T (mixture)",
    "context": "1M",
    "modalities": ["Text", "Vision", "Audio", "Video"],
    "domains": ["Multimodal", "Long Context"],
    "benchmarks": { "mmlu": 87.1 },
    "efficiency": "Streaming @ TPU v5p",
    "link": "https://blog.google/technology/google-deepmind/google-gemini-ai/",
    "timestamp": "2024-06-05T11:45:00Z"
  },
  {
    "id": "model-004",
    "name": "Llama 3.1 405B",
    "provider": "Meta",
    "params": "405B",
    "context": "128k",
    "modalities": ["Text"],
    "domains": ["Open Source", "Research"],
    "benchmarks": { "mmlu": 82.4 },
    "efficiency": "52 tokens / s @ custom cluster",
    "link": "https://ai.meta.com/blog/llama-3-1/",
    "timestamp": "2024-07-23T09:10:00Z"
  },
  {
    "id": "model-005",
    "name": "GPT-4o mini",
    "provider": "OpenAI",
    "params": "Mini (12B est.)",
    "context": "128k",
    "modalities": ["Text", "Vision", "Audio"],
    "domains": ["Assistants", "Edge"],
    "benchmarks": { "mmlu": 79.0 },
    "efficiency": "140 tokens / s @ iPhone 15 Pro",
    "link": "https://openai.com/index/introducing-gpt-4o-mini/",
    "timestamp": "2024-07-18T15:30:00Z"
  },
  {
    "id": "model-006",
    "name": "DeepSeek-R1",
    "provider": "DeepSeek",
    "params": "120B",
    "context": "64k",
    "modalities": ["Text"],
    "domains": ["Reasoning", "Math"],
    "benchmarks": { "mmlu": 85.2 },
    "efficiency": "63 tokens / s @ H800 cluster",
    "link": "https://deepseek.com/blog/deepseek-r1",
    "timestamp": "2024-08-08T08:00:00Z"
  },
  {
    "id": "model-007",
    "name": "Grok-2",
    "provider": "xAI",
    "params": "560B (Mixture)",
    "context": "256k",
    "modalities": ["Text", "Vision"],
    "domains": ["Real-time", "Search"],
    "benchmarks": { "mmlu": 84.7 },
    "efficiency": "Streaming @ xAI inference fabric",
    "link": "https://x.ai/blog/grok-2",
    "timestamp": "2024-08-10T13:45:00Z"
  }
]
